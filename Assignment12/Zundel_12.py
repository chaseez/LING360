# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EC-7ASuFSPJ1YZC_l3o8ydG2MUPRJKSy
"""

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from nltk import pos_tag, word_tokenize
from scipy.stats import pearsonr
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import json

def convert_json(filename):
    with open(f'{filename}', 'r') as file, open(f'updated_{filename}', 'w') as outfile:
        outfile.write('{ "data": [\n')
        lines = list(file)
        for i in range(len(lines)):
            lines[i] = lines[i].strip()
            updated_line = f'{lines[i]},\n' if i < len(lines) - 1 else f'{lines[i]}\n'
            outfile.write(updated_line)
        outfile.write(']\n}')

def count_adverbs(tagged_sentence):
    count = 0
    for word, tag in tagged_sentence:
        if tag == 'RB':
            count += 1

    return count


if __name__ == '__main__':
    # Turning the whole file into a .json file with "data" holding an array of json objects
    convert_json('yelp_AZ_2021.json')

    with open('updated_yelp_AZ_2021.json', 'r') as file:
        data = json.load(file)
    reviews = data['data']

    with open('reviews.csv', 'w') as outfile:
        # Header row
        header = ['stars', 'adverbs', 'sentiment']
        outfile.write(f"{','.join(header)}\n")

        # Initializing for sentiment analysis later
        sent_analyzer = SentimentIntensityAnalyzer()
        for review in reviews:
            stars = str(review['stars'])

            text = review['text'].strip()

            # Tokenize the word and put POS tags on the whole review
            tagged_sentence = pos_tag(word_tokenize(text))

            # Use the POS tags to find any adverbs
            adverb_count = str(count_adverbs(tagged_sentence))

            # Getting the polarity score for the review
            sentiment = str(sent_analyzer.polarity_scores(text)['compound'])

            # Collecting the information for each line in the csv
            line = [stars, adverb_count, sentiment]
            outfile.write(f"{','.join(line)}\n")

    df = pd.read_csv('reviews.csv')

    stars = df['stars'].values
    adverbs = df['adverbs'].values
    sentiment = df['sentiment'].values

    star_adverb_corr, _ = pearsonr(stars,adverbs)
    star_sentiment_corr, _ = pearsonr(stars, sentiment)

    sns.lmplot(x='stars', y='adverbs', data=df, fit_reg=True)
    plt.title('Correlation between stars and adverbs')
    plt.xlabel('Stars')
    plt.ylabel('Adverbs')
    plt.show()

    sns.lmplot(x='stars', y='sentiment', data=df, fit_reg=True)
    plt.title('Correlation between stars and sentiment')
    plt.xlabel('Stars')
    plt.ylabel('Sentiment')
    plt.show()